{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(generate_link())\n",
    "response = requests.get(generate_link())\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def scrape_all_details(page):\n",
    "  # # Send a GET request to the page and parse the HTML content\n",
    "\n",
    "  #   # response = requests.get(page)\n",
    "  #   # soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "  #   # Find all the elements that contain the product details\n",
    "  #   products = soup.find_all(\"div\", class_=\"bc-col-responsive bc-col-6\")\n",
    "\n",
    "  #   # Create an empty list to store the details\n",
    "  #   details_list = []\n",
    "\n",
    "  #   img_tags = soup.find_all(\"img\")\n",
    "  #   # list of image\n",
    "  #   urls = []\n",
    "  #   # Loop through the img tags and get the src attribute of each one\n",
    "  #   for i, img_tag in enumerate(img_tags):\n",
    "  #     try:\n",
    "  #       src = img_tag[\"src\"]\n",
    "  #       # print(src) # Print the image URL\n",
    "  #       urls.append(src)\n",
    "\n",
    "  #     except:\n",
    "  #       src = None\n",
    "  #       urls.append(src)\n",
    "  #       # print(src) # Print the image URL\n",
    "  #   cover_image = []\n",
    "  #   for image_link in urls:\n",
    "  #     if \"https://m.media-amazon.com/images/I\" in image_link or \".jpg\" in image_link:\n",
    "  #       # print(image_link)\n",
    "  #       cover_image.append(image_link)\n",
    "  #   if len(cover_image) % 10 != 0:\n",
    "  #     print(f\"Error: {len(cover_image)} images found\")\n",
    "  #     return None\n",
    "  #   else:\n",
    "  #     print(f\"Success: {len(cover_image)} images found\")\n",
    "\n",
    "  # # Loop through each product element and extract the details\n",
    "  #   for product in products:\n",
    "  #     # Try to find the title element and handle the exception if not found\n",
    "  #     try:\n",
    "  #       title = product.find(\"h3\", class_=\"bc-heading\").text.strip()\n",
    "  #     except AttributeError:\n",
    "  #       continue\n",
    "  #       # title = None\n",
    "  #     # Try to find the author element and handle the exception if not found\n",
    "  #     try:\n",
    "  #       author = product.find(\"li\", class_=\"authorLabel\").text.strip()\n",
    "  #     except AttributeError:\n",
    "  #       author = None\n",
    "  #     # Try to find the narrator element and handle the exception if not found\n",
    "  #     try:\n",
    "  #       narrator = product.find(\"li\", class_=\"narratorLabel\").text.strip()\n",
    "  #     except AttributeError:\n",
    "  #       narrator = None\n",
    "  #     try:\n",
    "  #       series = product.find(\"li\", class_=\"seriesLabel\").text.strip()\n",
    "  #     except AttributeError:\n",
    "  #       series = None\n",
    "  #     try:\n",
    "  #       length = product.find(\"li\", class_=\"runtimeLabel\").text.strip()\n",
    "  #       # length = hour_min_to_min(length)\n",
    "  #     except AttributeError:\n",
    "  #       length = None\n",
    "  #     try:\n",
    "  #       release_date = product.find(\"li\", class_=\"releaseDateLabel\").text.strip() \n",
    "  #       # release_date = string_to_date(release_date)\n",
    "  #     except AttributeError:\n",
    "  #       release_date = None\n",
    "  #     try:\n",
    "  #       language = product.find(\"li\", class_=\"languageLabel\").text.strip()\n",
    "  #     except AttributeError:\n",
    "  #       language = None\n",
    "\n",
    "  #     try:\n",
    "  #       ratings = product.find(\"li\", class_=\"ratingsLabel\").text.strip()\n",
    "  #       # ratings, votes = extract_rating(ratings)\n",
    "  #     except AttributeError:\n",
    "  #       ratings = None\n",
    "  #       votes = None\n",
    "\n",
    "  #     # Try to find the summary element and handle the exception if not found\n",
    "  #     try:\n",
    "  #       summary = product.find(\"p\", class_=\"bc-text\").text.strip()\n",
    "  #     except AttributeError:\n",
    "  #       summary = None\n",
    "\n",
    "  #     image = None\n",
    "\n",
    "  #     # Try to find the link element and handle the exception if not found\n",
    "  #     try:\n",
    "  #       link = product.find(\"a\", class_=\"bc-link bc-color-link\").get(\"href\")\n",
    "  #     except AttributeError:\n",
    "  #       link = None\n",
    "\n",
    "  #     # Create a dictionary with the product details\n",
    "  #     details_dict = {\n",
    "  #       \"title\": title,\n",
    "  #       \"author\": author,\n",
    "  #       \"narrator\": narrator,\n",
    "  #       \"series\": series,\n",
    "  #       \"length\": length,\n",
    "  #       \"release_date\": release_date,\n",
    "  #       \"language\": language,\n",
    "  #       \"ratings\": ratings,\n",
    "  #       # \"votes\": votes,\n",
    "  #       \"summary\": summary,\n",
    "  #       \"image\": image, # Add this line\n",
    "  #       \"link\": link # Add this line\n",
    "  #     }\n",
    "\n",
    "  #     # Format the values using strip and replace methods\n",
    "  #     for key, value in details_dict.items():\n",
    "  #       # Remove leading and trailing whitespaces\n",
    "  #       if value is None: continue\n",
    "  #       value = value.strip()\n",
    "  #       # Replace multiple whitespaces with a single space using re.sub\n",
    "  #       value = re.sub(\"\\s+\", \" \", value)\n",
    "  #       # Update the dictionary with the formatted value\n",
    "  #       details_dict[key] = value\n",
    "\n",
    "  #     # Append the dictionary to the list\n",
    "  #     details_list.append(details_dict)\n",
    "    \n",
    "  #   # add cover image to the dictionary in the list\n",
    "  #   for i in range(len(details_list)):\n",
    "  #     details_list[i][\"image\"] = cover_image[i]\n",
    "\n",
    "  #   # Return the list with all the details\n",
    "  #   return details_list\n",
    "\n",
    "\n",
    "def scrape_all_details(page):\n",
    "# Send a GET request to the page and parse the HTML content\n",
    "  # response = requests.get(page)\n",
    "  # soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "  # Find all the elements that contain the product details\n",
    "  products = soup.find_all(\"div\", class_=\"bc-col-responsive bc-col-6\")\n",
    "\n",
    "  # Create an empty list to store the details\n",
    "  details_list = []\n",
    "\n",
    "  img_tags = soup.find_all(\"img\")\n",
    "  # list of image\n",
    "  urls = []\n",
    "  # Loop through the img tags and get the src attribute of each one\n",
    "  for i, img_tag in enumerate(img_tags):\n",
    "    try:\n",
    "      src = img_tag[\"src\"]\n",
    "      # print(src) # Print the image URL\n",
    "      urls.append(src)\n",
    "\n",
    "    except:\n",
    "      src = None\n",
    "      urls.append(src)\n",
    "      # print(src) # Print the image URL\n",
    "  cover_image = []\n",
    "  for image_link in urls:\n",
    "    if \"https://m.media-amazon.com/images/I\" in image_link or \".jpg\" in image_link:\n",
    "      # print(image_link)\n",
    "      cover_image.append(image_link)\n",
    "  if len(cover_image) % 10 != 0:\n",
    "    print(f\"Error: {len(cover_image)} images found\")\n",
    "    return None\n",
    "  else:\n",
    "    print(f\"Success: {len(cover_image)} images found\")\n",
    "\n",
    "# Loop through each product element and extract the details\n",
    "  for product in products:\n",
    "    # Try to find the title element and handle the exception if not found\n",
    "    try:\n",
    "      title = product.find(\"h3\", class_=\"bc-heading\").text.strip()\n",
    "    except AttributeError:\n",
    "      title = None\n",
    "      continue\n",
    "    # Try to find the subtitle element and handle the exception if not found\n",
    "    try:\n",
    "      # get the li element with class subtitle\n",
    "      subtitle = product.find(\"li\", class_=\"bc-list-item subtitle\").text.strip()\n",
    "    except AttributeError:\n",
    "      subtitle = None\n",
    "\n",
    "    # Try to find the author element and handle the exception if not found\n",
    "    try:\n",
    "      author = product.find(\"li\", class_=\"authorLabel\").text.strip()\n",
    "    except AttributeError:\n",
    "      author = None\n",
    "    # Try to find the narrator element and handle the exception if not found\n",
    "    try:\n",
    "      narrator = product.find(\"li\", class_=\"narratorLabel\").text.strip()\n",
    "    except AttributeError:\n",
    "      narrator = None\n",
    "    try:\n",
    "      series = product.find(\"li\", class_=\"seriesLabel\").text.strip()\n",
    "    except AttributeError:\n",
    "      series = None\n",
    "    try:\n",
    "      length = product.find(\"li\", class_=\"runtimeLabel\").text.strip()\n",
    "    except AttributeError:\n",
    "      length = None\n",
    "    try:\n",
    "      release_date = product.find(\"li\", class_=\"releaseDateLabel\").text.strip() \n",
    "    except AttributeError:\n",
    "      release_date = None\n",
    "    try:\n",
    "      language = product.find(\"li\", class_=\"languageLabel\").text.strip()\n",
    "    except AttributeError:\n",
    "      language = None\n",
    "\n",
    "    try:\n",
    "      ratings = product.find(\"li\", class_=\"ratingsLabel\").text.strip()\n",
    "    except AttributeError:\n",
    "      ratings = None\n",
    "\n",
    "    # Try to find the summary element and handle the exception if not found\n",
    "    try:\n",
    "      summary = product.find(\"p\", class_=\"bc-text\").text.strip()\n",
    "    except AttributeError:\n",
    "      summary = None\n",
    "\n",
    "    image = None\n",
    "\n",
    "    # Try to find the link element and handle the exception if not found\n",
    "    try:\n",
    "      link = product.find(\"a\", class_=\"bc-link bc-color-link\").get(\"href\")\n",
    "    except AttributeError:\n",
    "      link = None\n",
    "\n",
    "    # Create a dictionary with the product details\n",
    "    details_dict = {\n",
    "      \"title\": title,\n",
    "      \"subtitle\": subtitle,\n",
    "      \"author\": author,\n",
    "      \"narrator\": narrator,\n",
    "      \"series\": series,\n",
    "      \"length\": length,\n",
    "      \"release_date\": release_date,\n",
    "      \"language\": language,\n",
    "      \"ratings\": ratings,\n",
    "      \"summary\": summary,\n",
    "      \"image\": image, # Add this line\n",
    "      \"link\": link # Add this line\n",
    "    }\n",
    "    # Format the values using strip and replace methods\n",
    "    for key, value in details_dict.items():\n",
    "      # Remove leading and trailing whitespaces\n",
    "      if value is None: continue\n",
    "      value = value.strip()\n",
    "      # Replace multiple whitespaces with a single space using re.sub\n",
    "      value = re.sub(\"\\s+\", \" \", value)\n",
    "      # Update the dictionary with the formatted value\n",
    "      details_dict[key] = value\n",
    "\n",
    "    # Append the dictionary to the list\n",
    "    details_list.append(details_dict)    \n",
    "    # modify length\n",
    "    details_dict['length'] = min_to_hour(details_dict['length'])\n",
    "    # modify ratings\n",
    "    details_dict['ratings'] = extract_rating(details_dict['ratings'])\n",
    "    # modify release date\n",
    "    details_dict['release_date'] = date_to_num(details_dict['release_date'])\n",
    "  \n",
    "  # add cover image to the dictionary in the list\n",
    "  for i in range(len(details_list)):\n",
    "    details_list[i][\"image\"] = cover_image[i]\n",
    "\n",
    "  # Return the list with all the details\n",
    "  return details_list\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "# Send a GET request to the URL of this page\n",
    "def generate_link(page=2, audible_programs=\"20956260011\", author_author=\"\", keywords=\"\", narrator=\"full-cast\", publisher=\"\", sort=\"review-rank\", title=\"\", pageSize=50):\n",
    "  base_url = \"https://www.audible.com/search?\"\n",
    "  params = {\n",
    "    \"audible_programs\": audible_programs,\n",
    "    \"author_author\": author_author,\n",
    "    \"keywords\": keywords,\n",
    "    \"narrator\": narrator,\n",
    "    \"pageSize\": pageSize,\n",
    "    \"publisher\": publisher,\n",
    "    \"sort\": sort,\n",
    "    \"title\": title,\n",
    "    \"ref\": \"a_search_l1_audible_programs_0\",\n",
    "    \"pf_rd_p\": \"daf0f1c8-2865-4989-87fb-15115ba5a6d2\",\n",
    "    \"pf_rd_r\": \"3CSM3Q3AG46QRQ0TVK0F\",\n",
    "    \"pageLoadId\": \"dELu6hUurPGV8fAu\",\n",
    "    \"creativeId\": \"9648f6bf-4f29-4fb4-9489-33163c0bb63e\"\n",
    "  }\n",
    "  if page > 1:\n",
    "    params[\"page\"] = page\n",
    "  query = \"&\".join([f\"{key}={value}\" for key, value in params.items()])\n",
    "  return base_url + query\n",
    "\n",
    "\n",
    "\n",
    "# hour and min to min\n",
    "def hour_min_to_min(tim):\n",
    "    if tim == None:\n",
    "        return None\n",
    "    elif 'min' not in tim:\n",
    "        return int(tim.split('Length: ')[1].split(' hr')[0])*60\n",
    "    elif 'hr' not in tim:\n",
    "        return int(tim.split('Length: ')[1].split(' min')[0])\n",
    "    else:\n",
    "        hr = tim.split('Length: ')[1].split(' hr')[0]\n",
    "        minute = tim.split(\"and \")[1].split(' min')[0]\n",
    "    return int(hr)*60 + int(minute)\n",
    "\n",
    "# convert string to date object\n",
    "def string_to_date(text):\n",
    "    '''\n",
    "    Convert string to date object\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    datetime.date\n",
    "        year in float\n",
    "        ex: 2013.2993150684931\n",
    "    '''\n",
    "    if text == None:\n",
    "        return None\n",
    "    elif 'Release date: ' in text:\n",
    "        month, day, year = text.split('Release date: ')[1].split('-')\n",
    "        year = \"20\"+year\n",
    "        # month, day, year = map(int, text.split('-'))\n",
    "        date =  datetime.date(int(year), int(month), int(day))\n",
    "    # check if text is float or int\n",
    "    elif text.isnumeric():\n",
    "        return text\n",
    "    return date.year+ date.month/12 + date.day/365\n",
    "\n",
    "# string_to_date(\"Release date: 03-18-13\")\n",
    "\n",
    "# convert string to date object\n",
    "def extract_rating(string):\n",
    "    '''\n",
    "    Extract rating and votes from string\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    string : str\n",
    "        String containing rating and votes\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary containing rating and votes\n",
    "    '''\n",
    "    if string == \"Not rated yet\" or string == None:\n",
    "        return None, None\n",
    "    string = string.split(' out of 5 stars ')\n",
    "    rating = float(string[0])\n",
    "    votes = int(string[1].split(' rating')[0].replace(',',''))\n",
    "    return rating, votes\n",
    "\n",
    "def scrape_all_details(page):\n",
    "# Send a GET request to the page and parse the HTML content\n",
    "  response = requests.get(page)\n",
    "  soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "  # Find all the elements that contain the product details\n",
    "  products = soup.find_all(\"div\", class_=\"bc-col-responsive bc-col-6\")\n",
    "\n",
    "  # Create an empty list to store the details\n",
    "  details_list = []\n",
    "\n",
    "  img_tags = soup.find_all(\"img\")\n",
    "  # list of image\n",
    "  urls = []\n",
    "  # Loop through the img tags and get the src attribute of each one\n",
    "  for i, img_tag in enumerate(img_tags):\n",
    "    try:\n",
    "      src = img_tag[\"src\"]\n",
    "      # print(src) # Print the image URL\n",
    "      urls.append(src)\n",
    "\n",
    "    except:\n",
    "      src = None\n",
    "      urls.append(src)\n",
    "      # print(src) # Print the image URL\n",
    "  cover_image = []\n",
    "  for image_link in urls:\n",
    "    if \"https://m.media-amazon.com/images/I\" in image_link or \".jpg\" in image_link:\n",
    "      # print(image_link)\n",
    "      cover_image.append(image_link)\n",
    "  if len(cover_image) % 10 != 0:\n",
    "    print(f\"Error: {len(cover_image)} images found\")\n",
    "    return None\n",
    "  else:\n",
    "    print(f\"Success: {len(cover_image)} images found\")\n",
    "\n",
    "# Loop through each product element and extract the details\n",
    "  for product in products:\n",
    "    # Try to find the title element and handle the exception if not found\n",
    "    try:\n",
    "      title = product.find(\"h3\", class_=\"bc-heading\").text.strip()\n",
    "    except AttributeError:\n",
    "      title = None\n",
    "      continue\n",
    "    # Try to find the subtitle element and handle the exception if not found\n",
    "    try:\n",
    "      subtitle = product.find(\"span\", class_=\"subtitle\").text.strip()\n",
    "    except AttributeError:\n",
    "      subtitle = None\n",
    "    # Try to find the author element and handle the exception if not found\n",
    "    try:\n",
    "      author = product.find(\"li\", class_=\"authorLabel\").text.strip()\n",
    "    except AttributeError:\n",
    "      author = None\n",
    "    # Try to find the narrator element and handle the exception if not found\n",
    "    try:\n",
    "      narrator = product.find(\"li\", class_=\"narratorLabel\").text.strip()\n",
    "    except AttributeError:\n",
    "      narrator = None\n",
    "    try:\n",
    "      series = product.find(\"li\", class_=\"seriesLabel\").text.strip()\n",
    "    except AttributeError:\n",
    "      series = None\n",
    "    try:\n",
    "      length = product.find(\"li\", class_=\"runtimeLabel\").text.strip()\n",
    "    except AttributeError:\n",
    "      length = None\n",
    "    try:\n",
    "      release_date = product.find(\"li\", class_=\"releaseDateLabel\").text.strip() \n",
    "    except AttributeError:\n",
    "      release_date = None\n",
    "    try:\n",
    "      language = product.find(\"li\", class_=\"languageLabel\").text.strip()\n",
    "    except AttributeError:\n",
    "      language = None\n",
    "\n",
    "    try:\n",
    "      ratings = product.find(\"li\", class_=\"ratingsLabel\").text.strip()\n",
    "    except AttributeError:\n",
    "      ratings = None\n",
    "\n",
    "    # Try to find the summary element and handle the exception if not found\n",
    "    try:\n",
    "      summary = product.find(\"p\", class_=\"bc-text\").text.strip()\n",
    "    except AttributeError:\n",
    "      summary = None\n",
    "\n",
    "    image = None\n",
    "\n",
    "    # Try to find the link element and handle the exception if not found\n",
    "    try:\n",
    "      link = product.find(\"a\", class_=\"bc-link bc-color-link\").get(\"href\")\n",
    "    except AttributeError:\n",
    "      link = None\n",
    "\n",
    "    # Create a dictionary with the product details\n",
    "    details_dict = {\n",
    "      \"title\": title,\n",
    "      \"subtitle\": subtitle,\n",
    "      \"author\": author,\n",
    "      \"narrator\": narrator,\n",
    "      \"series\": series,\n",
    "      \"length\": length,\n",
    "      \"release_date\": release_date,\n",
    "      \"language\": language,\n",
    "      \"ratings\": ratings,\n",
    "      \"summary\": summary,\n",
    "      \"image\": image, # Add this line\n",
    "      \"link\": link # Add this line\n",
    "    }\n",
    "\n",
    "    # Format the values using strip and replace methods\n",
    "    for key, value in details_dict.items():\n",
    "      # Remove leading and trailing whitespaces\n",
    "      value = value.strip()\n",
    "      # Replace multiple whitespaces with a single space using re.sub\n",
    "      value = re.sub(\"\\s+\", \" \", value)\n",
    "      # Update the dictionary with the formatted value\n",
    "      details_dict[key] = value\n",
    "\n",
    "    # Append the dictionary to the list\n",
    "    details_list.append(details_dict)\n",
    "  \n",
    "  # add cover image to the dictionary in the list\n",
    "  for i in range(len(details_list)):\n",
    "    details_list[i][\"image\"] = cover_image[i]\n",
    "\n",
    "  # Return the list with all the details\n",
    "  return details_list\n",
    "\n",
    "# data = scrape_all_details(generate_link())\n",
    "\n",
    "# Define a function to create a database and a table\n",
    "def create_db_table():\n",
    "  # Connect to the database file or create one if it does not exist\n",
    "  conn = sqlite3.connect('audiobooks.db')\n",
    "  # Create a cursor object to execute SQL commands\n",
    "  c = conn.cursor()\n",
    "  # Create a table with the columns as the keys of the scraped data\n",
    "  c.execute('''CREATE TABLE IF NOT EXISTS audiobooks (\n",
    "    title TEXT,\n",
    "    subtitle TEXT,\n",
    "    author TEXT,\n",
    "    narrator TEXT,\n",
    "    series TEXT,\n",
    "    length INTEGER,\n",
    "    release_date INTEGER,\n",
    "    language TEXT,\n",
    "    ratings INTEGER,\n",
    "    summary TEXT,\n",
    "    image TEXT,\n",
    "    link TEXT PRIMARY KEY)''')\n",
    "  # Commit the changes and close the connection\n",
    "  conn.commit()\n",
    "  conn.close()\n",
    "\n",
    "# Define a function to insert scraped data into the table\n",
    "def insert_data(data):\n",
    "  # Connect to the database file\n",
    "  conn = sqlite3.connect('audiobooks.db')\n",
    "  # Create a cursor object to execute SQL commands\n",
    "  c = conn.cursor()\n",
    "  # Loop through the data list and insert each item as a row\n",
    "  for item in data:\n",
    "    # Use a try-except block to handle duplicates\n",
    "    try:\n",
    "      # Insert the values of the item into the table\n",
    "      c.execute('''INSERT INTO audiobooks VALUES (\n",
    "        :title,\n",
    "        -- :subtitle, remove this from the database\n",
    "        :author,\n",
    "        :narrator,\n",
    "        :series,\n",
    "        :length,\n",
    "        :release_date,\n",
    "        :language,\n",
    "        :ratings,\n",
    "        :summary,\n",
    "        :image,\n",
    "        :link)''', item)\n",
    "      # Print a success message\n",
    "      print(f\"Inserted {item['title']} into the table\")\n",
    "    except sqlite3.IntegrityError:\n",
    "      # Print an error message if the link already exists in the table\n",
    "      print(f\"Duplicate link: {item['link']}\")\n",
    "  # Commit the changes and close the connection\n",
    "  conn.commit()\n",
    "  conn.close()\n",
    "\n",
    "# # Call the functions with the scraped data\n",
    "# create_db_table()\n",
    "# insert_data(data)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#   create_db_table()\n",
    "#   for i in range(8,8):\n",
    "#     data = scrape_all_details(generate_link(i))\n",
    "#     insert_data(data)\n",
    "#     print(f\"Page {i} scraped successfully\")\n",
    "#     time.sleep(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sqlite3 and datetime modules\n",
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Define a class to get the data from the database\n",
    "class DataGetter:\n",
    "\n",
    "  # Define a constructor that takes a database name as an argument\n",
    "  def __init__(self, db_name):\n",
    "    # Connect to the database and create a cursor object\n",
    "    self.conn = sqlite3.connect(db_name)\n",
    "    self.cur = self.conn.cursor()\n",
    "\n",
    "  # Define a function that converts the data from the database into a list of dictionaries\n",
    "  def get_data(self):\n",
    "    # Execute a query to select all columns except subtitle from the table\n",
    "    self.cur.execute(\"SELECT title, author, narrator, series, length, release_date, language, ratings, summary, image, link FROM audiobooks\")\n",
    "    # Fetch all the rows from the query result\n",
    "    rows = self.cur.fetchall()\n",
    "    # Create an empty list to store the converted data\n",
    "    data = []\n",
    "    # Loop through each row\n",
    "    for row in rows:\n",
    "      # Create an empty dictionary to store the row data\n",
    "      item = {}\n",
    "      # Assign the values of each column to the corresponding keys in the dictionary\n",
    "      item['title'] = row[0]\n",
    "      item['author'] = row[1]\n",
    "      item['narrator'] = row[2]\n",
    "      item['series'] = row[3]\n",
    "      item['length'] = hour_min_to_min(row[4])\n",
    "      item['release_date'] = string_to_date(row[5])\n",
    "      item['language'] = row[6]\n",
    "      item['rating'], item[\"votes\"] = extract_rating(row[7])\n",
    "      item['summary'] = row[8]\n",
    "      item['image'] = row[9]\n",
    "      item['link'] = row[10]\n",
    "      # Append the dictionary to the data list\n",
    "      data.append(item)\n",
    "    # Return the data list\n",
    "    return data\n",
    "\n",
    "  # Define a function that closes the database connection\n",
    "  def close(self):\n",
    "    # Close the cursor and the connection objects\n",
    "    self.cur.close()\n",
    "    self.conn.close()\n",
    "audible = DataGetter('audiobooks.db')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\saket\\Documents\\GitHub\\Pyhton\\web scraping\\test.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/saket/Documents/GitHub/Pyhton/web%20scraping/test.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m audible\u001b[39m.\u001b[39;49mget_data()\n",
      "\u001b[1;32mc:\\Users\\saket\\Documents\\GitHub\\Pyhton\\web scraping\\test.ipynb Cell 8\u001b[0m in \u001b[0;36mDataGetter.get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saket/Documents/GitHub/Pyhton/web%20scraping/test.ipynb#W4sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m item[\u001b[39m'\u001b[39m\u001b[39mnarrator\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m row[\u001b[39m2\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saket/Documents/GitHub/Pyhton/web%20scraping/test.ipynb#W4sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m item[\u001b[39m'\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m row[\u001b[39m3\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/saket/Documents/GitHub/Pyhton/web%20scraping/test.ipynb#W4sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m item[\u001b[39m'\u001b[39m\u001b[39mlength\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m hour_min_to_min(row[\u001b[39m4\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saket/Documents/GitHub/Pyhton/web%20scraping/test.ipynb#W4sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m item[\u001b[39m'\u001b[39m\u001b[39mrelease_date\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m string_to_date(row[\u001b[39m5\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saket/Documents/GitHub/Pyhton/web%20scraping/test.ipynb#W4sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m item[\u001b[39m'\u001b[39m\u001b[39mlanguage\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m row[\u001b[39m6\u001b[39m]\n",
      "\u001b[1;32mc:\\Users\\saket\\Documents\\GitHub\\Pyhton\\web scraping\\test.ipynb Cell 8\u001b[0m in \u001b[0;36mhour_min_to_min\u001b[1;34m(tim)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saket/Documents/GitHub/Pyhton/web%20scraping/test.ipynb#W4sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saket/Documents/GitHub/Pyhton/web%20scraping/test.ipynb#W4sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m tim:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/saket/Documents/GitHub/Pyhton/web%20scraping/test.ipynb#W4sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mint\u001b[39m(tim\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39mLength: \u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m hr\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m])\u001b[39m*\u001b[39m\u001b[39m60\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saket/Documents/GitHub/Pyhton/web%20scraping/test.ipynb#W4sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mhr\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m tim:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saket/Documents/GitHub/Pyhton/web%20scraping/test.ipynb#W4sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mint\u001b[39m(tim\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39mLength: \u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m min\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m])\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = AudiobookDB()\n",
    "data = db.get_all_data()\n",
    "db.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "\n",
    "for i in data:\n",
    "    image_link = i[10]\n",
    "    title = i[0]\n",
    "    star = i[8]\n",
    "    \n",
    "    # conver the title to a valid file name\n",
    "    title = title.replace(\":\", \"\")\n",
    "    # download the image to a folder\n",
    "    image = Image.open(requests.get(image_link, stream=True).raw)\n",
    "    # add metadata to the image\n",
    "\n",
    "    file_loc = f\"image/{title}.jpg\"\n",
    "    # there a image folder in the same directory\n",
    "    # check if the image is already downloaded\n",
    "    try:\n",
    "        with open(file_loc) as f:\n",
    "            pass\n",
    "    except FileNotFoundError:\n",
    "        # if not downloaded, download it\n",
    "        image.save(file_loc)\n",
    "        print(f\"{i[0]}.jpg downloaded\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import sqlite3 and datetime modules\n",
    "# import sqlite3\n",
    "# import datetime\n",
    "# # Import re module for regular expressions\n",
    "# import re\n",
    "\n",
    "# # Define a class to get the data from the database\n",
    "# class DataGetter:\n",
    "\n",
    "#   # Define a constructor that takes a database name as an argument\n",
    "#   def __init__(self, db_name):\n",
    "#     # Connect to the database and create a cursor object\n",
    "#     self.conn = sqlite3.connect(db_name)\n",
    "#     self.cur = self.conn.cursor()\n",
    "\n",
    "#   # Define a function that converts the data from the database into a list of dictionaries\n",
    "#   def get_data(self):\n",
    "#     # Execute a query to select all columns except subtitle from the table\n",
    "#     self.cur.execute(\"SELECT title, author, narrator, series, length, release_date, language, ratings, summary, image, link FROM audiobooks\")\n",
    "#     # Fetch all the rows from the query result\n",
    "#     rows = self.cur.fetchall()\n",
    "#     # Create an empty list to store the converted data\n",
    "#     data = []\n",
    "#     # Loop through each row\n",
    "#     for row in rows:\n",
    "#       # Create an empty dictionary to store the row data\n",
    "#       item = {}\n",
    "#       # Assign the values of each column to the corresponding keys in the dictionary\n",
    "#       item['title'] = row[0]\n",
    "#       item['author'] = row[1]\n",
    "#       item['narrator'] = row[2]\n",
    "#       item['series'] = row[3]\n",
    "#       # Check if the length column is None and assign None if so, otherwise convert it from string to integer in minutes\n",
    "#       if row[4] == None:\n",
    "#         item['length'] = None\n",
    "#       else:\n",
    "#         hours, minutes = map(int, row[4].split(' hrs and '))\n",
    "#         item['length'] = hours * 60 + minutes\n",
    "#       # Check if the release date column is None and assign None if so, otherwise convert it from string to datetime object\n",
    "#       if row[5] == None:\n",
    "#         item['release_date'] = None\n",
    "#       else:\n",
    "#         month, day, year = map(int, row[5].split('-'))\n",
    "#         item['release_date'] = datetime.date(year, month, day)\n",
    "#       item['language'] = row[6]\n",
    "#       # Check if the ratings column is None and assign None if so, otherwise split it by space and get the first and last elements as rating and votes\n",
    "#       if row[7] == None:\n",
    "#         item['rating'] = None\n",
    "#         item['votes'] = None\n",
    "#       else:\n",
    "#         try:\n",
    "#             rating, votes = re.findall(r'\\d[\\d.,]*', row[7])\n",
    "#         except:\n",
    "#             print(row[7])\n",
    "#       item['summary'] = row[8]\n",
    "#       item['image'] = row[9]\n",
    "#       item['link'] = row[10]\n",
    "#       # Append the dictionary to the data list\n",
    "#       data.append(item)\n",
    "#     # Return the data list\n",
    "#     return data\n",
    "\n",
    "#   # Define a function that closes the database connection\n",
    "#   def close(self):\n",
    "#     # Close the cursor and the connection objects\n",
    "#     self.cur.close()\n",
    "#     self.conn.close()\n",
    "\n",
    "\n",
    "# # Define a function to get the data from the database\n",
    "# def get_data(db_name):\n",
    "#     # Create an instance of the DataGetter class\n",
    "#     getter = DataGetter(db_name)\n",
    "#     # Call the get_data method\n",
    "#     data = getter.get_data()\n",
    "#     # Close the database connection\n",
    "#     getter.close()\n",
    "#     # Return the data\n",
    "#     return data\n",
    "# get_data('audiobooks.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in data:\n",
    "#     print(i[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string = \"4.5 out of 5 stars 2,010 ratings\"\n",
    "# string = \"5 out of 5 stars 1 rating\"\n",
    "\n",
    "# for i in data:\n",
    "#     try:\n",
    "#         print(i[8], '-->', extract_rating(i[8]))\n",
    "#         extract_rating(i[8])\n",
    "#     except:\n",
    "#         print(i[8])\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're Alive: A Story of Survival, the Third Season\n",
      "N/A\n",
      "By: Kc Wayland\n",
      "Narrated by: full cast\n",
      "Series: We’re Alive: A Story of Survival, Book 3\n",
      "Length: 11 hrs and 31 mins\n",
      "Release date: 03-18-13\n",
      "Language: English\n",
      "5 out of 5 stars 1,432 ratings\n",
      "N/A\n",
      "https://m.media-amazon.com/images/I/51Xt2BYA5vL._SL500_.jpg\n",
      "/pd/Were-Alive-A-Story-of-Survival-the-Third-Season-Audiobook/B00BUTFLGS\n",
      "(\"We're Alive: A Story of Survival, the Third Season\", 'N/A', 'By: Kc Wayland', 'Narrated by: full cast', 'Series: We’re Alive: A Story of Survival, Book 3', 'Length: 11 hrs and 31 mins', 'Release date: 03-18-13', 'Language: English', '5 out of 5 stars 1,432 ratings', 'N/A', 'https://m.media-amazon.com/images/I/51Xt2BYA5vL._SL500_.jpg', '/pd/Were-Alive-A-Story-of-Survival-the-Third-Season-Audiobook/B00BUTFLGS')\n"
     ]
    }
   ],
   "source": [
    "# for i in data[4:]:\n",
    "#     for ii in i:\n",
    "#         print(ii)\n",
    "#     print(i)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\saket\\Documents\\GitHub\\Pyhton\\web scraping\\test.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saket/Documents/GitHub/Pyhton/web%20scraping/test.ipynb#W6sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcur\u001b[39m.\u001b[39mclose()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saket/Documents/GitHub/Pyhton/web%20scraping/test.ipynb#W6sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconn\u001b[39m.\u001b[39mclose()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/saket/Documents/GitHub/Pyhton/web%20scraping/test.ipynb#W6sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m audible \u001b[39m=\u001b[39m DataGetter(\u001b[39m'\u001b[39;49m\u001b[39maudiobooks.db\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mget_data()\n",
      "\u001b[1;32mc:\\Users\\saket\\Documents\\GitHub\\Pyhton\\web scraping\\test.ipynb Cell 9\u001b[0m in \u001b[0;36mDataGetter.get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saket/Documents/GitHub/Pyhton/web%20scraping/test.ipynb#W6sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m   item[\u001b[39m'\u001b[39m\u001b[39mvotes\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saket/Documents/GitHub/Pyhton/web%20scraping/test.ipynb#W6sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/saket/Documents/GitHub/Pyhton/web%20scraping/test.ipynb#W6sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m   rating, _, _, votes, _ \u001b[39m=\u001b[39m row[\u001b[39m7\u001b[39m]\u001b[39m.\u001b[39msplit()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saket/Documents/GitHub/Pyhton/web%20scraping/test.ipynb#W6sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m   item[\u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(rating)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saket/Documents/GitHub/Pyhton/web%20scraping/test.ipynb#W6sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m   item[\u001b[39m'\u001b[39m\u001b[39mvotes\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(votes\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 5)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imageKOZ.jpg downloaded\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Define a class to interact with the database\n",
    "class AudiobookDB:\n",
    "  # Define the constructor method to initialize the connection and cursor\n",
    "  def __init__(self):\n",
    "    self.conn = sqlite3.connect('audiobooks.db')\n",
    "    self.c = self.conn.cursor()\n",
    "\n",
    "  # Define a method to get all the data from the table\n",
    "  def get_all_data(self):\n",
    "    # Execute a SQL query to select all the rows from the table\n",
    "    self.c.execute('SELECT * FROM audiobooks')\n",
    "    # Fetch all the results and return them as a list of tuples\n",
    "    data = self.c.fetchall()\n",
    "    return data\n",
    "\n",
    "  # Define a method to get a specific number of data from the table\n",
    "  def get_limit_data(self, limit):\n",
    "    # Execute a SQL query to select the first n rows from the table\n",
    "    self.c.execute(f'SELECT * FROM audiobooks LIMIT {limit}')\n",
    "    # Fetch all the results and return them as a list of tuples\n",
    "    data = self.c.fetchall()\n",
    "    return data\n",
    "\n",
    "  # Define a method to get data based on a filter condition\n",
    "  def get_filter_data(self, column, value):\n",
    "    # Execute a SQL query to select the rows that match the condition\n",
    "    self.c.execute(f'SELECT * FROM audiobooks WHERE {column} = ?', (value,))\n",
    "    # Fetch all the results and return them as a list of tuples\n",
    "    data = self.c.fetchall()\n",
    "    return data\n",
    "\n",
    "  # Define a method to close the connection\n",
    "  def close_connection(self):\n",
    "    self.conn.close()\n",
    "\n",
    "# Create an instance of the class\n",
    "# db = AudiobookDB()\n",
    "\n",
    "# # # Test the methods\n",
    "# # # print(db.get_all_data())\n",
    "# # print(db.get_limit_data(1))\n",
    "# # print(db.get_filter_data('language', 'English'))\n",
    "\n",
    "# # Close the connection\n",
    "# import sqlite3\n",
    "\n",
    "# # Define a function to get data based on multiple parameters with default values\n",
    "# def get_custom_data(title=None, subtitle=None, author=None, narrator=None, series=None, length=None, release_date=None, language=None, ratings=None, summary=None, image=None, link=None):\n",
    "#   # Connect to the database file\n",
    "#   conn = sqlite3.connect('audiobooks.db')\n",
    "#   # Create a cursor object to execute SQL commands\n",
    "#   c = conn.cursor()\n",
    "#   # Create a list of parameters and their values\n",
    "#   params = [('title', title), ('subtitle', subtitle), ('author', author), ('narrator', narrator), ('series', series), ('length', length), ('release_date', release_date), ('language', language), ('ratings', ratings), ('summary', summary), ('image', image), ('link', link)]\n",
    "#   # Create a list of conditions based on the parameters that are not None\n",
    "#   conditions = [f\"{param[0]} = ?\" for param in params if param[1] is not None]\n",
    "#   # Create a list of values based on the parameters that are not None\n",
    "#   values = [param[1] for param in params if param[1] is not None]\n",
    "#   # Create a SQL query to select the rows that match the conditions\n",
    "#   query = f\"SELECT * FROM audiobooks WHERE {' AND '.join(conditions)}\"\n",
    "#   # Execute the query with the values\n",
    "#   c.execute(query, values)\n",
    "#   # Fetch all the results and return them as a list of tuples\n",
    "#   data = c.fetchall()\n",
    "#   # Close the connection\n",
    "#   conn.close()\n",
    "#   return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('KOZ', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', '5 out of 5 stars 2,010 ratings', 'N/A', 'https://m.media-amazon.com/images/I/517I-u-1NGL._SL500_.jpg', '/pd/KOZ-Podcast/B0B4F665LR')]\n",
      "[('Revenge of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Joe Brack, Elizabeth Jernigan, Dylan Lynch, David Coyne, Tim Getman, Richard Rohan, Terence Aselford, Michael Glenn, Christopher Graybill', 'Series: Mountain Man (Johnstone), Book 4, Dramatized Adaptation', 'Length: 6 hrs and 4 mins', 'Release date: 11-14-20', 'Language: English', '5 out of 5 stars 35 ratings', 'N/A', 'https://m.media-amazon.com/images/I/61CyC23FFwL._SL500_.jpg', '/pd/Revenge-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/1648805698'), ('Journey of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Andy Clemence, Steven Carpenter, Tim Getman, Terence Aselford, Christopher Graybill, Richard Rohan, Michael John Casey, David Coyne, James Konicek', 'Series: Mountain Man (Johnstone), Book 5, Dramatized Adaptation', 'Length: 6 hrs and 19 mins', 'Release date: 11-14-20', 'Language: English', '5 out of 5 stars 32 ratings', 'N/A', 'https://m.media-amazon.com/images/I/614otPUQ5bL._SL500_.jpg', '/pd/Journey-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/164880571X'), ('Trail of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Richard Rohan, Terence Aselford, David Coyne, Elizabeth Jernigan, Tim Carlin, Danny Gavigan, Tim Getman, Eric Messner, Andy Clemence', 'Series: Mountain Man (Johnstone), Book 3, Dramatized Adaptation', 'Length: 6 hrs and 18 mins', 'Release date: 11-14-20', 'Language: English', '5 out of 5 stars 30 ratings', 'N/A', 'https://m.media-amazon.com/images/I/61h58kY9lsL._SL500_.jpg', '/pd/Trail-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/1648805671'), ('The Last Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Sherri Simpson, David Coyne, Dylan Lynch, Thomas Penny, Tim Getman, James Konicek, Jason Stiles, Christopher Graybill, Jonathan Watkins', 'Series: Mountain Man (Johnstone), Book 1, Dramatized Adaptation', 'Length: 4 hrs and 33 mins', 'Release date: 11-14-20', 'Language: English', '5 out of 5 stars 51 ratings', 'N/A', 'https://m.media-amazon.com/images/I/51B+tOzmoAL._SL500_.jpg', '/pd/The-Last-Mountain-Man-Dramatized-Adaptation-Audiobook/1648805639'), ('Law of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Michael Glenn, Andy Clemence, Steven Carpenter, Jonathan Watkins, Christopher Graybill, David Coyne, Richard Rohan, Casie Platt, James Konicek', 'Series: Mountain Man (Johnstone), Book 6, Dramatized Adaptation', 'Length: 5 hrs and 50 mins', 'Release date: 11-14-20', 'Language: English', '5 out of 5 stars 29 ratings', 'N/A', 'https://m.media-amazon.com/images/I/61ltix+WxRL._SL500_.jpg', '/pd/Law-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/1648805736'), ('War of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Terence Aselford, Michael Glenn, Andy Clemence, Elizabeth Jernigan, James Konicek, Christopher Graybill, Michael John Casey, David Coyne, Jonathan Watkins', 'Series: Mountain Man (Johnstone), Book 7, Dramatized Adaptation', 'Length: 5 hrs and 8 mins', 'Release date: 11-14-20', 'Language: English', '5 out of 5 stars 29 ratings', 'N/A', 'https://m.media-amazon.com/images/I/612yvvmDmlL._SL500_.jpg', '/pd/War-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/1648805752'), ('Return of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Elizabeth Jernigan, Terence Aselford, Richard Rohan, Tim Getman, Steven Carpenter, David Coyne, Tim Carlin, Thomas Penny, Lily Beacon', 'Series: Mountain Man (Johnstone), Book 2, Dramatized Adaptation', 'Length: 3 hrs and 40 mins', 'Release date: 11-14-20', 'Language: English', '5 out of 5 stars 28 ratings', 'N/A', 'https://m.media-amazon.com/images/I/51rhfmJRfxL._SL500_.jpg', '/pd/Return-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/1648805655'), ('Pursuit of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, David Coyne, Terence Aselford, Richard Rohan, Joe Brack, Ken Jackson, Dylan Lynch, Tim Getman, Tom Simpson, Elizabeth Jernigan', 'Series: Mountain Man (Johnstone), Book 9, Dramatized Adaptation', 'Length: 4 hrs and 50 mins', 'Release date: 11-14-20', 'Language: English', '5 out of 5 stars 24 ratings', 'N/A', 'https://m.media-amazon.com/images/I/61Z5N9-mZNL._SL500_.jpg', '/pd/Pursuit-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/1648805795'), ('Courage of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Terence Aselford, Elizabeth Jernigan, Dylan Lynch, Ren Casey, Nanette Savard, James Konicek, David Coyne, Tim Getman, Joe Brack', 'Series: Mountain Man (Johnstone), Book 10, Dramatized Adaptation', 'Length: 4 hrs and 44 mins', 'Release date: 11-14-20', 'Language: English', '5 out of 5 stars 20 ratings', 'N/A', 'https://m.media-amazon.com/images/I/613jbRyQWpL._SL500_.jpg', '/pd/Courage-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/1648805817'), ('Blood of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Terence Aselford, Eric Messner, James Konicek, Christopher Graybill, David Coyne, Michael Glenn, Elizabeth Jernigan, Richard Rohan, Tim Getman', 'Series: Mountain Man (Johnstone), Book 11, Dramatized Adaptation', 'Length: 5 hrs and 19 mins', 'Release date: 11-11-20', 'Language: English', '5 out of 5 stars 20 ratings', 'N/A', 'https://m.media-amazon.com/images/I/61yAOLm-6XL._SL500_.jpg', '/pd/Blood-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/1648805833'), ('Code of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Michael Glenn, Steven Carpenter, Andy Clemence, Richard Rohan, Thomas Penny, Tim Getman, Michael John Casey, David Coyne, Elizabeth Jernigan', 'Series: Mountain Man (Johnstone), Book 8, Dramatized Adaptation', 'Length: 5 hrs and 5 mins', 'Release date: 11-14-20', 'Language: English', '5 out of 5 stars 28 ratings', 'N/A', 'https://m.media-amazon.com/images/I/61LIGzEluXL._SL500_.jpg', '/pd/Code-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/1648805779'), ('Trek of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Tim Getman, Elizabeth Jernigan, Drew Kopas, Tim Carlin, James Konicek, Michael Glenn, Richard Rohan, Ken Jackson, James Keegan', 'Series: Mountain Man (Johnstone), Book 29, Dramatized Adaptation', 'Length: 4 hrs and 39 mins', 'Release date: 11-12-20', 'Language: English', '5 out of 5 stars 17 ratings', 'N/A', 'https://m.media-amazon.com/images/I/61Ov2cVDAYL._SL500_.jpg', '/pd/Trek-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/1648806236'), ('Spirit of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Tim Carlin, Elizabeth Jernigan, Tim Getman, David Coyne, Ren Kasey, Jeff Baker, Joe Brack, Terence Aselford, Dylan Lynch', 'Series: Mountain Man (Johnstone), Book 16, Dramatized Adaptation', 'Length: 5 hrs and 17 mins', 'Release date: 11-11-20', 'Language: English', '5 out of 5 stars 16 ratings', 'N/A', 'https://m.media-amazon.com/images/I/61QRYwuoo3L._SL500_.jpg', '/pd/Spirit-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/1648805930'), ('The Beginning [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, James Lewis, Terence Aselford, Lily Beacon, Mort Shelby, Christopher Graybill, Bradley Smith, Alyssa Wilmoth, Michael Glenn, Scott Graham, Scott McCormick, Elizabeth Jernigan', 'Series: Smoke Jensen, Book The Beginning [Dramatized Adaptation], Book 1', 'Length: 5 hrs and 46 mins', 'Release date: 11-11-20', 'Language: English', '5 out of 5 stars 20 ratings', 'N/A', 'https://m.media-amazon.com/images/I/515PLN5QhWL._SL500_.jpg', '/pd/The-Beginning-Dramatized-Adaptation-Audiobook/1648806058'), ('Warpath of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Tim Getman, Elizabeth Jernigan, Drew Kopas, Tim Carlin, James Konicek, Michael Glenn, Richard Rohan, Ken Jackson, James Keegan', 'Series: Mountain Man (Johnstone), Book 28, Dramatized Adaptation', 'Length: 5 hrs', 'Release date: 11-11-20', 'Language: English', '5 out of 5 stars 15 ratings', 'N/A', 'https://m.media-amazon.com/images/I/61HkONIxhEL._SL500_.jpg', '/pd/Warpath-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/164880621X'), ('Ordeal of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Ren Casey, Elizabeth Jernigan, Laura Quinn, Nanette Savard, Tim Getman, Joe Brack, Thomas Penny, Ken Jackson, Andy Clemence', 'Series: Mountain Man (Johnstone), Book 17, Dramatized Adaptation', 'Length: 5 hrs and 17 mins', 'Release date: 11-11-20', 'Language: English', '5 out of 5 stars 16 ratings', 'N/A', 'https://m.media-amazon.com/images/I/51XAphRqMQL._SL500_.jpg', '/pd/Ordeal-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/1648805957'), ('Fury of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Steven Carpenter, Joe Brack, David Coyne, Elizabeth Jernigan, Ren Casey, Thomas Penny, Nanette Savard, Tim Carlin, Dylan Lynch', 'Series: Mountain Man (Johnstone), Book 12, Dramatized Adaptation', 'Length: 5 hrs and 6 mins', 'Release date: 11-11-20', 'Language: English', '5 out of 5 stars 18 ratings', 'N/A', 'https://m.media-amazon.com/images/I/61QJmQtup2L._SL500_.jpg', '/pd/Fury-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/164880585X'), ('Rage of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Elizabeth Jernigan, Andy Clemence, Eric Messner, Michael John Casey, David Coyne, Tim Getman, Michael Glenn, Joe Brack, Tim Carlin', 'Series: Mountain Man (Johnstone), Book 13, Dramatized Adaptation', 'Length: 5 hrs and 8 mins', 'Release date: 11-11-20', 'Language: English', '5 out of 5 stars 23 ratings', 'N/A', 'https://m.media-amazon.com/images/I/51ne2+sTPKL._SL500_.jpg', '/pd/Rage-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/1648805876'), ('Power of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Joe Brack, Steven Carpenter, Yasmin Tuazon, Michael Glenn, Terence Aselford, James Konicek, David Coyne, Tim Getman, Eric Messner', 'Series: Mountain Man (Johnstone), Book 15, Dramatized Adaptation', 'Length: 5 hrs and 17 mins', 'Release date: 11-11-20', 'Language: English', '5 out of 5 stars 22 ratings', 'N/A', 'https://m.media-amazon.com/images/I/61e9XGjNKgL._SL500_.jpg', '/pd/Power-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/1648805914'), ('Cunning of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Joe Brack, Steven Carpenter, Yasmin Tuazon, Michael Glenn, Terence Aselford, James Konicek, David Coyne, Tim Getman, Eric Messner', 'Series: Mountain Man (Johnstone), Book 14, Dramatized Adaptation', 'Length: 5 hrs and 22 mins', 'Release date: 11-11-20', 'Language: English', '5 out of 5 stars 16 ratings', 'N/A', 'https://m.media-amazon.com/images/I/51y7VruJNiL._SL500_.jpg', '/pd/Cunning-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/1648805892'), ('Guns of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Drew Kopas, Tim Getman, Elizabeth Jernigan, David Coyne, James Konicek, Michael Glenn, Joe Brack, Steven Carpenter, Tim Carlin', 'Series: Mountain Man (Johnstone), Book 24, Dramatized Adaptation', 'Length: 4 hrs and 34 mins', 'Release date: 11-11-20', 'Language: English', '5 out of 5 stars 15 ratings', 'N/A', 'https://m.media-amazon.com/images/I/51renWbtl2L._SL500_.jpg', '/pd/Guns-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/1648806139'), ('Blackfoot Messiah [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, Richard Rohan, Terence Aselford, Ken Jackson, David Coyne, Colleen Delany, Thomas Penny, Tim Carlin, Peter Stray, Elisabeth Demery, James Lewis', 'Series: First Mountain Man [Dramatized Adaptation], Book 7', 'Length: 6 hrs and 4 mins', 'Release date: 11-12-20', 'Language: English', '5 out of 5 stars 14 ratings', 'N/A', 'https://m.media-amazon.com/images/I/51QMhNe+AlL._SL500_.jpg', '/pd/Blackfoot-Messiah-Dramatized-Adaptation-Audiobook/1648802621'), ('Ambush of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Drew Kopas, Tim Getman, Elizabeth Jernigan, Richard Rohan, Michael John Casey, Terence Aselford, Kimberly Gilbert, James Konicek, Steven Carpenter', 'Series: Mountain Man (Johnstone), Book 31, Dramatized Adaptation', 'Length: 4 hrs and 48 mins', 'Release date: 11-12-20', 'Language: English', '5 out of 5 stars 13 ratings', 'N/A', 'https://m.media-amazon.com/images/I/61O3kQDD-SL._SL500_.jpg', '/pd/Ambush-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/1648806279'), ('Triumph of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Christopher Scheeren, Dan Stevens, Steven Carpenter, Tony Nam, David Coyne, Terence Aselford, Michael Glenn, Yasmin Tuazon, Dylan Lynch', 'Series: Mountain Man (Johnstone), Book 18, Dramatized Adaptation', 'Length: 5 hrs and 45 mins', 'Release date: 11-11-20', 'Language: English', '5 out of 5 stars 12 ratings', 'N/A', 'https://m.media-amazon.com/images/I/51-AD3P15oL._SL500_.jpg', '/pd/Triumph-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/1648805973'), ('This Violent Land [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, James Lewis, Mort Shelby, Thomas Keegan, Richard Rohan, Elizabeth Jernigan, David Coyne, Lily Beacon, Bradley Smith, Bruce Alan Rauscher, Thomas Penny, Sherri Edelen', 'Series: Smoke Jensen, Book The Beginning [Dramatized Adaptation], Book 2', 'Length: 5 hrs and 30 mins', 'Release date: 11-11-20', 'Language: English', '4.5 out of 5 stars 18 ratings', 'N/A', 'https://m.media-amazon.com/images/I/51Vrm0UYjGL._SL500_.jpg', '/pd/This-Violent-Land-Dramatized-Adaptation-Audiobook/1648806074'), ('Vengeance of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Thomas Penny, Dan Stevens, Tony Nam, Jeff Allin, Christopher Scheeren, Tim Carlin, Richard Rohan, Elizabeth Jernigan, Kate Foster', 'Series: Mountain Man (Johnstone), Book 19, Dramatized Adaptation', 'Length: 4 hrs and 52 mins', 'Release date: 11-11-20', 'Language: English', '4.5 out of 5 stars 18 ratings', 'N/A', 'https://m.media-amazon.com/images/I/61+mSdJPsML._SL500_.jpg', '/pd/Vengeance-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/164880599X'), ('Battle of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Tim Getman, James Konicek, Elizabeth Jernigan, Andy Clemence, Steven Carpenter, Michael John Casey, Richard Rohan, Drew Kopas, Thomas Penny', 'Series: Mountain Man (Johnstone), Book 21, Dramatized Adaptation', 'Length: 5 hrs and 3 mins', 'Release date: 11-11-20', 'Language: English', '4.5 out of 5 stars 16 ratings', 'N/A', 'https://m.media-amazon.com/images/I/51+XXYZjHBL._SL500_.jpg', '/pd/Battle-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/1648806031'), ('Quest of the Mountain Man [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, James Lewis, Elizabeth Jernigan, Drew Kopas, Tim Getman, Tim Carlin, Richard Rohan, Joe Brack, Thomas Penny, Steven Carpenter, Christopher Graybill', 'Series: Mountain Man (Johnstone), Book 30, Dramatized Adaptation', 'Length: 4 hrs and 40 mins', 'Release date: 11-12-20', 'Language: English', '5 out of 5 stars 11 ratings', 'N/A', 'https://m.media-amazon.com/images/I/61ei+Lt9gtL._SL500_.jpg', '/pd/Quest-of-the-Mountain-Man-Dramatized-Adaptation-Audiobook/1648806252'), ('Those Jensen Boys! [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Mort Shelby, Scott Graham, Jonathan Feuer, Colleen Delany, James Konicek, Kimberly Gilbert, Dylan Lynch, Andy Brownstein, Terence Aselford, Chris Davenport, Christopher Scheeren', 'Series: Those Jensen Boys!, Book 1, Dramatized Adaptation', 'Length: 5 hrs and 38 mins', 'Release date: 11-14-20', 'Language: English', '5 out of 5 stars 9 ratings', 'N/A', 'https://m.media-amazon.com/images/I/61jgQlq05LL._SL500_.jpg', '/pd/Those-Jensen-Boys-Dramatized-Adaptation-Audiobook/1648804950'), ('Twelve Dead Men [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Nanette Savard, Scott Graham, Robbie Gay, Tim Getman, Christopher Walker, Tracy Olivera, Thomas Keegan, Bradley Smith, Gregory Linington, Steven Carpenter, Nick DePinto', 'Series: Those Jensen Boys!, Book 3, Dramatized Adaptation', 'Length: 5 hrs and 4 mins', 'Release date: 11-14-20', 'Language: English', '5 out of 5 stars 10 ratings', 'N/A', 'https://m.media-amazon.com/images/I/51XHyL+IN9L._SL500_.jpg', '/pd/Twelve-Dead-Men-Dramatized-Adaptation-Audiobook/1648804993'), ('Behind The Iron [Dramatized Adaptation]', 'N/A', 'By: William W. Johnstone', 'Narrated by: full cast, Nanette Savard, Chris Genebach, Nick DePinto, James Konicek, Michael Glenn, Andy Clemence, Eric Messner, Kenyatta Rogers, Elizabeth Jernigan, David Jourdan, Dylan Lynch', 'Series: Hank Fallon, Book 2', 'Length: 5 hrs and 21 mins', 'Release date: 11-14-20', 'Language: English', '4 out of 5 stars 5 ratings', 'N/A', 'https://m.media-amazon.com/images/I/51XdEjsqGXL._SL500_.jpg', '/pd/Behind-The-Iron-Dramatized-Adaptation-Audiobook/1648814581')]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Test the function with different parameters\n",
    "print(get_custom_data(title='KOZ'))\n",
    "print(get_custom_data(author='By: William W. Johnstone'))\n",
    "print(get_custom_data(language='English'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://m.media-amazon.com/images/I/517I-u-1NGL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51POjQXrnVL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51ywcR6OqkL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51-D+0blRnS._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51Xt2BYA5vL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61CyC23FFwL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51g3AinAJNL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51pCOQAUu4L._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51NyNt9PePS._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51qO2LV-ilL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/515rqFN7PJL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61i0TYaZ9pL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/614otPUQ5bL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51HAoKblnpL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51TjnQD6ILL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51FvcRRvyUL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61tqfwb3YML._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61h58kY9lsL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51B+tOzmoAL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61ltix+WxRL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/612yvvmDmlL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/5196zyzA2fS._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51rhfmJRfxL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51txvtQZg7L._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51wah8yjZ7L._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51+VMSMxJPL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/41Gjypfjf-L._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61Z5N9-mZNL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51NGkd6hOLL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51uh6OvizhL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51Aay40lkCS._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51rhjUWCxjL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/516yPwKkg8S._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51Y7qsBCEqS._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61dspT0lFFL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51+pIdAoNzL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61QCEt+Y1sL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/615aEqepZXL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51ZzMa3EjqS._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61ABo-PGRKL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51XCvYylKgL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/613jbRyQWpL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61yAOLm-6XL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/518-2ZATH+L._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61F9ICiBMxL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61LIGzEluXL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/617uAiuEEyL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61fPehw7H+L._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51P8xc0fm3L._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/510rzj21-HL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61FlPJedDSL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61Ov2cVDAYL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51QCUotjBqS._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/519sRqjapeL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51Y6i7oZ0uL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61QRYwuoo3L._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/5130B23y-uL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/619lWsxOFvL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51N9TH5AHoL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51a3JwCcwQL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51REw+1gCtL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61KlAnPv24L._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51yulaBs3aL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61rW7GXzlHL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51U6CV6R+hL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/515PLN5QhWL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51dImhuxV8L._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51pV-DEUMGL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51vtyyFXNPL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61HkONIxhEL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51XAphRqMQL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51YEje8kl9L._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/516fm3WV4EL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51dt0qc7oRS._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51W843ecnEL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61QJmQtup2L._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51FPn8VgyJL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51hG7x2NjiS._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51w3GEdmMdL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51YZYTtGuSL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51ne2+sTPKL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61e9XGjNKgL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51y7VruJNiL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51UfVOmmk3L._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61cJndKQotL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/419FUdRi3fL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51KKC-bgTbL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51renWbtl2L._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51nQAqwhwlL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61ezpxsQ82L._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/41JwOcpvnPL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51bezsw+muL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51KXX-kdHjL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/5106IgEtRjL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/41KfV5MaUqL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51TY5UZSt3L._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51thjhJHMTL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/514ezP0+DSL._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/61IMPrrSt+L._SL500_.jpg\n",
      "https://m.media-amazon.com/images/I/51YYDlZywVL._SL500_.jpg\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301\n"
     ]
    }
   ],
   "source": [
    "# no = 1\n",
    "# # print the database\n",
    "# conn = sqlite3.connect(\"audiobooks.db\")\n",
    "# cur = conn.cursor()\n",
    "# cur.execute(\"SELECT * FROM audiobooks\")\n",
    "# results = cur.fetchall()\n",
    "# for row in results:\n",
    "#     # print(row)\n",
    "#     no += 1\n",
    "# conn.close()\n",
    "# print(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = (\"https://m.media-amazon.com/images/I/517I-u-1NGL._SL500_.jpg\",\n",
    "#         \"https://m.media-amazon.com/images/I/51POjQXrnVL._SL500_.jpg\",\n",
    "#         \"https://m.media-amazon.com/images/I/51ywcR6OqkL._SL500_.jpg\",\n",
    "#         \"https://m.media-amazon.com/images/I/51-D+0blRnS._SL500_.jpg\",\n",
    "#         \"https://m.media-amazon.com/images/I/51Xt2BYA5vL._SL500_.jpg\",\n",
    "#         \"https://m.media-amazon.com/images/I/61CyC23FFwL._SL500_.jpg\",\n",
    "#         \"https://m.media-amazon.com/images/I/51g3AinAJNL._SL500_.jpg\",\n",
    "#         \"https://m.media-amazon.com/images/I/51pCOQAUu4L._SL500_.jpg\",\n",
    "#         \"https://m.media-amazon.com/images/I/51NyNt9PePS._SL500_.jpg\",\n",
    "#         \"https://m.media-amazon.com/images/I/51qO2LV-ilL._SL500_.jpg\",\n",
    "#         \"https://m.media-amazon.com/images/I/515rqFN7PJL._SL500_.jpg\",\n",
    "#         \"https://m.media-amazon.com/images/I/61i0TYaZ9pL._SL500_.jpg\",\n",
    "#         \"https://m.media-amazon.com/images/I/614otPUQ5bL._SL500_.jpg\",\n",
    "#         \"https://m.media-amazon.com/images/I/51HAoKblnpL._SL500_.jpg\",\n",
    "#         \"https://m.media-amazon.com/images/I/51TjnQD6ILL._SL500_.jpg\",\n",
    "#         \"https://m.media-amazon.com/images/I/51FvcRRvyUL._SL500_.jpg\",\n",
    "#         \"https://m.media-amazon.com/images/I/61tqfwb3YML._SL500_.jpg\",\n",
    "#         \"https://m.media-amazon.com/images/I/61h58kY9lsL._SL500_.jpg\",\n",
    "#         \"https://m.media-amazon.com/images/I/51B+tOzmoAL._SL500_.jpg\",\n",
    "#         \"https://m.media-amazon.com/images/I/61ltix+WxRL._SL500_.jpg\",\n",
    "#     )\n",
    "\n",
    "# # download images\n",
    "# for image_link in images:\n",
    "#     image_name = image_link.split(\"/\")[-1]\n",
    "#     with open(image_name, \"wb\") as f:\n",
    "#         f.write(requests.get(image_link).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "\n",
    "# Define the URL of the website\n",
    "# url = generate_link # Replace this with your desired URL\n",
    "\n",
    "# # Make a request to the website and get the HTML content\n",
    "# response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "# html = response.text\n",
    "\n",
    "# # Parse the HTML content using BeautifulSoup\n",
    "# soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "\n",
    "# response = requests.get(generate_link())\n",
    "# soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "\n",
    "# Find all the img tags in the HTML content\n",
    "\n",
    "    # Open the image URL using requests and Pillow\n",
    "    # image = Image.open(requests.get(src, stream=True).raw)\n",
    "    \n",
    "    # Save the image to a folder with a unique name\n",
    "    # image.save(f\"image{i}.jpg\") # You can change the folder and file name as you wish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the soup object to a file\n",
    "with open(\"soup.html\", \"w\") as file:\n",
    "    file.write(str(soup))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import scrapy\n",
    "# import scrapy\n",
    "\n",
    "# # Import the CrawlerProcess: for running the spider\n",
    "# from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "# # Import the Twisted reactor\n",
    "# from twisted.internet import reactor\n",
    "\n",
    "# # Define a class for your spider\n",
    "# class GithubSpider(scrapy.Spider):\n",
    "#   # Give your spider a name\n",
    "#   name = \"github_spider\"\n",
    "#   # Define a list of URLs to start scraping from\n",
    "#   start_urls = [generate_link()]\n",
    "\n",
    "#   # Define a method to parse the response from each URL\n",
    "#   def parse(self, response):\n",
    "#     # Find all the elements that contain the product details\n",
    "#     products = response.xpath(\"//div[@class='bc-col-responsive bc-col-6']\")\n",
    "\n",
    "#     # Loop through each product element and extract the details\n",
    "#     for product in products:\n",
    "#       # Try to find the title element and handle the exception if not found\n",
    "#       try:\n",
    "#         title = product.xpath(\".//h3/text()\").get().strip()\n",
    "#       except AttributeError:\n",
    "#         title = None\n",
    "#       # Try to find the subtitle element and handle the exception if not found\n",
    "#       try:\n",
    "#         subtitle = product.xpath(\".//span[@class='subtitle']/text()\").get().strip()\n",
    "#       except AttributeError:\n",
    "#         subtitle = None\n",
    "#       # Try to find the author element and handle the exception if not found\n",
    "#       try:\n",
    "#         author = product.xpath(\".//li[@class='authorLabel']/text()\").get().strip()\n",
    "#       except AttributeError:\n",
    "#         author = None\n",
    "#       # Try to find the narrator element and handle the exception if not found\n",
    "#       try:\n",
    "#         narrator = product.xpath(\".//li[@class='narratorLabel']/text()\").get().strip()\n",
    "#       except AttributeError:\n",
    "#         narrator = None\n",
    "#       try:\n",
    "#         series = product.xpath(\".//li[@class='seriesLabel']/text()\").get().strip()\n",
    "#       except AttributeError:\n",
    "#         series = None\n",
    "#       try:\n",
    "#         length = product.xpath(\".//li[@class='runtimeLabel']/text()\").get().strip()\n",
    "#       except AttributeError:\n",
    "#         length = None\n",
    "#       try:\n",
    "#         release_date = product.xpath(\".//li[@class='releaseDateLabel']/text()\").get().strip()\n",
    "#       except AttributeError:\n",
    "#         release_date = None\n",
    "#       try:\n",
    "#         language = product.xpath(\".//li[@class='languageLabel']/text()\").get().strip()\n",
    "#       except AttributeError:\n",
    "#         language = None\n",
    "\n",
    "#       try:\n",
    "#         ratings = product.xpath(\".//li[@class='ratingsLabel']/text()\").get().strip()\n",
    "#       except AttributeError:\n",
    "#         ratings = None\n",
    "\n",
    "#       # Try to find the summary element and handle the exception if not found\n",
    "#       try:\n",
    "#         summary = product.xpath(\".//p/text()\").get().strip()\n",
    "#       except AttributeError:\n",
    "#         summary = None\n",
    "      \n",
    "#       # Try to find the image element and handle the exception if not found\n",
    "#       try:\n",
    "#         # Get the src attribute of the img tag\n",
    "#         image = product.xpath(\".//img/@src\").get()\n",
    "#       except AttributeError:\n",
    "#         image = None\n",
    "\n",
    "#       # Try to find the link element and handle the exception if not found\n",
    "#       try:\n",
    "#         link = product.xpath(\".//a/@href\").get()\n",
    "#       except AttributeError:\n",
    "#         link = None\n",
    "\n",
    "#       # Create a dictionary with the product details\n",
    "#       details_dict = {\n",
    "#         \"title\": title,\n",
    "#         \"subtitle\": subtitle,\n",
    "#         \"author\": author,\n",
    "#         \"narrator\": narrator,\n",
    "#         \"series\": series,\n",
    "#         \"length\": length,\n",
    "#         \"release_date\": release_date,\n",
    "#         \"language\": language,\n",
    "#         \"ratings\": ratings,\n",
    "#         \"summary\": summary,\n",
    "#         \"image\": image, # Add this line\n",
    "#         \"link\": link # Add this line\n",
    "#       }\n",
    "\n",
    "#       # Yield or return the dictionary\n",
    "#       yield details_dict\n",
    "\n",
    "\n",
    "\n",
    "# # Create an instance of the CrawlerProcess: process\n",
    "# process = CrawlerProcess()\n",
    "\n",
    "# # Run the spider\n",
    "# process.crawl(GithubSpider)\n",
    "# process.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the libraries\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# from PIL import Image\n",
    "\n",
    "# # Define the URL of the website\n",
    "# # url = generate_link # Replace this with your desired URL\n",
    "\n",
    "# # # Make a request to the website and get the HTML content\n",
    "# # response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "# # html = response.text\n",
    "\n",
    "# # # Parse the HTML content using BeautifulSoup\n",
    "# # soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "\n",
    "# response = requests.get(generate_link(), headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "# soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "\n",
    "# # Find all the img tags in the HTML content\n",
    "\n",
    "#     # Open the image URL using requests and Pillow\n",
    "#     # image = Image.open(requests.get(src, stream=True).raw)\n",
    "    \n",
    "#     # Save the image to a folder with a unique name\n",
    "#     # image.save(f\"image{i}.jpg\") # You can change the folder and file name as you wish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('title', \"We're Alive: A Story of Survival, the Third Season\")\n",
      "('subtitle', 'N/A')\n",
      "('author', 'By: Kc Wayland')\n",
      "('narrator', 'Narrated by: full cast')\n",
      "('series', 'Series: We’re Alive: A Story of Survival, Book 3')\n",
      "('length', 'Length: 11 hrs and 31 mins')\n",
      "('release_date', 'Release date: 03-18-13')\n",
      "('language', 'Language: English')\n",
      "('ratings', '5 out of 5 stars 1,432 ratings')\n",
      "('summary', 'N/A')\n"
     ]
    }
   ],
   "source": [
    "# for audiobook in data[5:]:\n",
    "#     for key, value in audiobook.items():\n",
    "#         # print(key, value)\n",
    "#         pass\n",
    "\n",
    "# data5 = {'title': \"We're Alive: A Story of Survival, the Third Season\",\n",
    "#  'subtitle': 'N/A',\n",
    "#  'author': 'By:\\n                                    Kc Wayland',\n",
    "#  'narrator': 'Narrated by:\\n                                      full cast',\n",
    "#  'series': 'Series:\\n                                      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        \\n            \\n                \\n                \\n            \\n            \\n        \\n        \\n            \\n        \\n        We’re Alive: A Story of Survival, Book 3',\n",
    "#  'length': 'Length: 11 hrs and 31 mins',\n",
    "#  'release_date': 'Release date:\\n                                    03-18-13',\n",
    "#  'language': 'Language:\\n                                      English',\n",
    "#  'ratings': '5 out of 5 stars\\n1,432 ratings',\n",
    "#  'summary': 'N/A'}\n",
    "\n",
    "# # Loop through the values in the dictionary\n",
    "# for key, value in data5.items():\n",
    "#   # Remove leading and trailing whitespaces\n",
    "#   value = value.strip()\n",
    "#   # Replace multiple \\n with a single space\n",
    "#   value = value.replace(\"\\n\", \" \")\n",
    "#   # Update the dictionary with the formatted value\n",
    "#   data5[key] = value\n",
    "\n",
    "# # Import the re module\n",
    "# import re\n",
    "\n",
    "# # Loop through the values in the dictionary\n",
    "# for key, value in data5.items():\n",
    "#   # Remove leading and trailing whitespaces\n",
    "#   value = value.strip()\n",
    "#   # Replace multiple whitespaces with a single space using re.sub\n",
    "#   value = re.sub(\"\\s+\", \" \", value)\n",
    "#   # Update the dictionary with the formatted value\n",
    "#   data5[key] = value\n",
    "\n",
    "# # Print the formatted dictionary\n",
    "# for i in data5.items():\n",
    "#   print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# # read a html page with beautiful soup\n",
    "# file = open('test.html')\n",
    "# soup = BeautifulSoup(file, 'html.parser')\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_link(page=1, audible_programs=\"20956260011\", author_author=\"\", keywords=\"\", narrator=\"full-cast\", publisher=\"\", sort=\"review-rank\", title=\"\"):\n",
    "#   base_url = \"https://www.audible.com/search?\"\n",
    "#   params = {\n",
    "#     \"audible_programs\": audible_programs,\n",
    "#     \"author_author\": author_author,\n",
    "#     \"keywords\": keywords,\n",
    "#     \"narrator\": narrator,\n",
    "#     \"publisher\": publisher,\n",
    "#     \"sort\": sort,\n",
    "#     \"title\": title,\n",
    "#     \"ref\": \"a_search_l1_audible_programs_0\",\n",
    "#     \"pf_rd_p\": \"daf0f1c8-2865-4989-87fb-15115ba5a6d2\",\n",
    "#     \"pf_rd_r\": \"3CSM3Q3AG46QRQ0TVK0F\",\n",
    "#     \"pageLoadId\": \"dELu6hUurPGV8fAu\",\n",
    "#     \"creativeId\": \"9648f6bf-4f29-4fb4-9489-33163c0bb63e\"\n",
    "#   }\n",
    "#   if page > 1:\n",
    "#     params[\"page\"] = page\n",
    "#   query = \"&\".join([f\"{key}={value}\" for key, value in params.items()])\n",
    "#   return base_url + query\n",
    "\n",
    "# generate_link()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
